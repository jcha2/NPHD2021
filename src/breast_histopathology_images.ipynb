{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48103891",
   "metadata": {},
   "source": [
    "# Try using CoAtNet w/ Breast Histopathology Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5272608e",
   "metadata": {},
   "source": [
    "* The original dataset consisted of 162 whole mount slide images of Breast Cancer (BCa) specimens scanned at 40x. From that, 277,524 patches of size 50 x 50 were extracted (198,738 IDC negative and 78,786 IDC positive). Each patch’s file name is of the format: uxXyYclassC.png — > example 10253idx5x1351y1101class0.png . Where u is the patient ID (10253idx5), X is the x-coordinate of where this patch was cropped from, Y is the y-coordinate of where this patch was cropped from, and C indicates the class where 0 is non-IDC and 1 is IDC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9931e332",
   "metadata": {},
   "source": [
    "## 1) Get Image Data & Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "469cdabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "04ab50e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec6c5b9f2394ce0a9d87208ba48d5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78786\n",
      "198738\n",
      "277524\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/bis/211105_CSH_MPL/kaggleBreast/\"\n",
    "\n",
    "ids = os.listdir(path)\n",
    "paths_1 = []\n",
    "paths_0 = []\n",
    "for id in tqdm(ids):\n",
    "    try:\n",
    "        files1 = os.listdir(path + id + '/1/')\n",
    "        files0 = os.listdir(path + id + '/0/')\n",
    "        for x in files1:\n",
    "            paths_1.append(path + id + '/1/' + x)\n",
    "        for x in files0:\n",
    "            paths_0.append(path + id + '/0/' + x)\n",
    "    except:\n",
    "        FileNotFoundError\n",
    "print(len(paths_1))\n",
    "print(len(paths_0))\n",
    "print(len(paths_0+paths_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6145df22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "100\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "#NPHD - positive 5000, negative 5000\n",
    "\n",
    "import random\n",
    "\n",
    "random.shuffle(paths_1)\n",
    "random.shuffle(paths_0)\n",
    "train_paths = paths_0[:200] + paths_1[:200]\n",
    "valid_paths = paths_0[200:250]+paths_1[200:250]\n",
    "test_paths = paths_0[250:500]+paths_1[250:500]\n",
    "print(len(train_paths))\n",
    "print(len(valid_paths))\n",
    "print(len(test_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2f90c3b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c952ad45a641958541ec74ba71e612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f17a7ea8e414bf08f91d551fa3b2cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45516dd390e148a59638661ba4f71715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#image to array\n",
    "#processing 277524 imgs take about 10 mins\n",
    "#processing 10000 imgs take about 1 mins\n",
    "import keras_preprocessing.image as IMAGE\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import  TensorDataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([64, 64]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "train_images=[]\n",
    "for i in tqdm(train_paths):\n",
    "    label = int(i[-5]) # class1.png --> 1\n",
    "    img = transform(IMAGE.load_img(i, target_size=(64,64)))\n",
    "    train_images.append((img,label))\n",
    "\n",
    "valid_images=[]\n",
    "for i in tqdm(valid_paths):\n",
    "    label = int(i[-5]) # class1.png --> 1\n",
    "    img = transform(IMAGE.load_img(i, target_size=(64,64)))\n",
    "    valid_images.append((img,label))    \n",
    "\n",
    "test_images=[]\n",
    "for i in tqdm(test_paths):\n",
    "    label = int(i[-5]) # class1.png --> 1\n",
    "    img = transform(IMAGE.load_img(i, target_size=(64,64)))\n",
    "    test_images.append((img,label))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "393e91ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train img # 400\n",
      "test img # 500\n"
     ]
    }
   ],
   "source": [
    "print(\"train img #\",len(train_images))\n",
    "print(\"test img #\",len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3b162763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import  TensorDataset, DataLoader\n",
    "\n",
    "dataloaders = {}\n",
    "dataloaders['train'] = DataLoader(train_images, batch_size=16, shuffle=True)\n",
    "dataloaders['valid'] = DataLoader(valid_images, batch_size=len(valid_images), shuffle=True)\n",
    "dataloaders['test'] = DataLoader(test_images, batch_size=len(test_images), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea9f69",
   "metadata": {},
   "source": [
    "## 2) Try CoAtNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8612699",
   "metadata": {},
   "source": [
    "def coatnet_0():<br/>\n",
    "    num_blocks = [2, 2, 3, 5, 2]            # L<br/>\n",
    "    channels = [64, 96, 192, 384, 768]      # D<br/>\n",
    "    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)<br/>\n",
    "\n",
    "<br/>\n",
    "def coatnet_1():<br/>\n",
    "    num_blocks = [2, 2, 6, 14, 2]           # L<br/>\n",
    "    channels = [64, 96, 192, 384, 768]      # D<br/>\n",
    "    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)<br/>\n",
    "\n",
    "<br/>\n",
    "def coatnet_2():<br/>\n",
    "    num_blocks = [2, 2, 6, 14, 2]           # L<br/>\n",
    "    channels = [128, 128, 256, 512, 1026]   # D<br/>\n",
    "    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)<br/>\n",
    "\n",
    "<br/>\n",
    "def coatnet_3():<br/>\n",
    "    num_blocks = [2, 2, 6, 14, 2]           # L<br/>\n",
    "    channels = [192, 192, 384, 768, 1536]   # D<br/>\n",
    "    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)<br/>\n",
    "\n",
    "\n",
    "def coatnet_4():<br/>\n",
    "    num_blocks = [2, 2, 12, 28, 2]          # L<br/>\n",
    "    channels = [192, 192, 384, 768, 1536]   # D<br/>\n",
    "    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5cff78cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches: 25\n"
     ]
    }
   ],
   "source": [
    "# Print total batches\n",
    "total_batches = len(dataloaders[\"train\"])\n",
    "print(f\"Total batches: {total_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f1919019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoAtNet(\n",
      "  (s0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): GELU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): GELU()\n",
      "    )\n",
      "  )\n",
      "  (s1): Sequential(\n",
      "    (0): MBConv(\n",
      "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (proj): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv): PreNorm(\n",
      "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (fn): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): GELU()\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): GELU()\n",
      "          (6): SE(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "              (1): GELU()\n",
      "              (2): Linear(in_features=16, out_features=256, bias=False)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (7): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): MBConv(\n",
      "      (conv): PreNorm(\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (fn): Sequential(\n",
      "          (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): GELU()\n",
      "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): GELU()\n",
      "          (6): SE(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=384, out_features=24, bias=False)\n",
      "              (1): GELU()\n",
      "              (2): Linear(in_features=24, out_features=384, bias=False)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (7): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (s2): Sequential(\n",
      "    (0): MBConv(\n",
      "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (proj): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (conv): PreNorm(\n",
      "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (fn): Sequential(\n",
      "          (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): GELU()\n",
      "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): GELU()\n",
      "          (6): SE(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=384, out_features=24, bias=False)\n",
      "              (1): GELU()\n",
      "              (2): Linear(in_features=24, out_features=384, bias=False)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (7): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): MBConv(\n",
      "      (conv): PreNorm(\n",
      "        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (fn): Sequential(\n",
      "          (0): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): GELU()\n",
      "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): GELU()\n",
      "          (6): SE(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=768, out_features=48, bias=False)\n",
      "              (1): GELU()\n",
      "              (2): Linear(in_features=48, out_features=768, bias=False)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (7): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): MBConv(\n",
      "      (conv): PreNorm(\n",
      "        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (fn): Sequential(\n",
      "          (0): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): GELU()\n",
      "          (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): GELU()\n",
      "          (6): SE(\n",
      "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc): Sequential(\n",
      "              (0): Linear(in_features=768, out_features=48, bias=False)\n",
      "              (1): GELU()\n",
      "              (2): Linear(in_features=48, out_features=768, bias=False)\n",
      "              (3): Sigmoid()\n",
      "            )\n",
      "          )\n",
      "          (7): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (s3): Sequential(\n",
      "    (0): Transformer(\n",
      "      (pool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (pool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (proj): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (attn): Sequential(\n",
      "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (to_qkv): Linear(in_features=192, out_features=768, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=384, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=4, iw=4)\n",
      "      )\n",
      "      (ff): Sequential(\n",
      "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=384, out_features=768, bias=True)\n",
      "              (1): GELU()\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "              (3): Linear(in_features=768, out_features=384, bias=True)\n",
      "              (4): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=4, iw=4)\n",
      "      )\n",
      "    )\n",
      "    (1): Transformer(\n",
      "      (attn): Sequential(\n",
      "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=384, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=4, iw=4)\n",
      "      )\n",
      "      (ff): Sequential(\n",
      "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (1): GELU()\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "              (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (4): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=4, iw=4)\n",
      "      )\n",
      "    )\n",
      "    (2): Transformer(\n",
      "      (attn): Sequential(\n",
      "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=384, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=4, iw=4)\n",
      "      )\n",
      "      (ff): Sequential(\n",
      "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (1): GELU()\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "              (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (4): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=4, iw=4)\n",
      "      )\n",
      "    )\n",
      "    (3): Transformer(\n",
      "      (attn): Sequential(\n",
      "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=384, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=4, iw=4)\n",
      "      )\n",
      "      (ff): Sequential(\n",
      "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (1): GELU()\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "              (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (4): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=4, iw=4)\n",
      "      )\n",
      "    )\n",
      "    (4): Transformer(\n",
      "      (attn): Sequential(\n",
      "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=384, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=4, iw=4)\n",
      "      )\n",
      "      (ff): Sequential(\n",
      "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (1): GELU()\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "              (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (4): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=4, iw=4)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (s4): Sequential(\n",
      "    (0): Transformer(\n",
      "      (pool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (pool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (proj): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (attn): Sequential(\n",
      "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (to_qkv): Linear(in_features=384, out_features=768, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=768, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=2, iw=2)\n",
      "      )\n",
      "      (ff): Sequential(\n",
      "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=768, out_features=1536, bias=True)\n",
      "              (1): GELU()\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "              (3): Linear(in_features=1536, out_features=768, bias=True)\n",
      "              (4): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=2, iw=2)\n",
      "      )\n",
      "    )\n",
      "    (1): Transformer(\n",
      "      (attn): Sequential(\n",
      "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): Attention(\n",
      "            (attend): Softmax(dim=-1)\n",
      "            (to_qkv): Linear(in_features=768, out_features=768, bias=False)\n",
      "            (to_out): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=768, bias=True)\n",
      "              (1): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=2, iw=2)\n",
      "      )\n",
      "      (ff): Sequential(\n",
      "        (0): Rearrange('b c ih iw -> b (ih iw) c')\n",
      "        (1): PreNorm(\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (fn): FeedForward(\n",
      "            (net): Sequential(\n",
      "              (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (1): GELU()\n",
      "              (2): Dropout(p=0.0, inplace=False)\n",
      "              (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (4): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Rearrange('b (ih iw) c -> b c ih iw', ih=2, iw=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=768, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Init CoAtNet model\n",
    "import torch.nn as nn\n",
    "from coatnet import coatnet_0,coatnet_1,coatnet_2,coatnet_3,coatnet_4\n",
    "from coatnet import CoAtNet\n",
    "\n",
    "\n",
    "#coatnet_4\n",
    "num_blocks = [2, 2, 3, 5, 2]            # L\n",
    "channels = [64, 96, 192, 384, 768]      # D\n",
    "block_types=['C', 'C', 'T', 'T']        # 'C' for MBConv, 'T' for Transformer\n",
    "model = CoAtNet((64,64), 3, num_blocks, channels, num_classes = 2) \n",
    "\n",
    "#loss - cross entropy\n",
    "#optimizer - adam\n",
    "# loss_fn = nn.MSELoss()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define Optimizer - 이해 필요\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.0001,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=10e-8,\n",
    "    amsgrad=False,\n",
    ")\n",
    "\n",
    "# Print model info\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a764ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def div(i1, i2):\n",
    "    return i1/i2 if i2 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d4917b80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training loss: 1.0034186840057373\n",
      "Validation loss: 0.03731130436062813\n",
      "Validation accuracy: 0.5\n",
      "Epoch 1\n",
      "Training loss: 0.41606879234313965\n",
      "Validation loss: 0.01618383266031742\n",
      "Validation accuracy: 0.86\n",
      "Epoch 2\n",
      "Training loss: 0.36123818159103394\n",
      "Validation loss: 0.014746812172234058\n",
      "Validation accuracy: 0.86\n",
      "Epoch 3\n",
      "Training loss: 0.26743653416633606\n",
      "Validation loss: 0.020006917417049408\n",
      "Validation accuracy: 0.83\n",
      "Epoch 4\n",
      "Training loss: 0.22217343747615814\n",
      "Validation loss: 0.032366249710321426\n",
      "Validation accuracy: 0.79\n",
      "Epoch 5\n",
      "Training loss: 0.1629261076450348\n",
      "Validation loss: 0.023033270612359047\n",
      "Validation accuracy: 0.87\n",
      "Epoch 6\n",
      "Training loss: 0.07543262094259262\n",
      "Validation loss: 0.020127832889556885\n",
      "Validation accuracy: 0.85\n",
      "Epoch 7\n",
      "Training loss: 0.032308418303728104\n",
      "Validation loss: 0.03599844127893448\n",
      "Validation accuracy: 0.79\n",
      "Epoch 8\n",
      "Training loss: 0.02464905008673668\n",
      "Validation loss: 0.03917780518531799\n",
      "Validation accuracy: 0.82\n",
      "Epoch 9\n",
      "Training loss: 0.11016647517681122\n",
      "Validation loss: 0.052692219614982605\n",
      "Validation accuracy: 0.75\n",
      "Epoch 10\n",
      "Training loss: 0.08725281804800034\n",
      "Validation loss: 0.023242782801389694\n",
      "Validation accuracy: 0.85\n",
      "Epoch 11\n",
      "Training loss: 0.03569070249795914\n",
      "Validation loss: 0.03560233116149902\n",
      "Validation accuracy: 0.82\n",
      "Epoch 12\n",
      "Training loss: 0.010762003250420094\n",
      "Validation loss: 0.03597765788435936\n",
      "Validation accuracy: 0.82\n",
      "Epoch 13\n",
      "Training loss: 0.0008877249201759696\n",
      "Validation loss: 0.03598203510046005\n",
      "Validation accuracy: 0.85\n",
      "Epoch 14\n",
      "Training loss: 0.007613863795995712\n",
      "Validation loss: 0.039130400866270065\n",
      "Validation accuracy: 0.86\n",
      "Epoch 15\n",
      "Training loss: 0.07294847071170807\n",
      "Validation loss: 0.03481518104672432\n",
      "Validation accuracy: 0.8\n",
      "Epoch 16\n",
      "Training loss: 0.008163453079760075\n",
      "Validation loss: 0.03833039104938507\n",
      "Validation accuracy: 0.83\n",
      "Epoch 17\n",
      "Training loss: 0.03083222173154354\n",
      "Validation loss: 0.05097382143139839\n",
      "Validation accuracy: 0.72\n",
      "Epoch 18\n",
      "Training loss: 0.02265860140323639\n",
      "Validation loss: 0.037693195044994354\n",
      "Validation accuracy: 0.83\n",
      "Epoch 19\n",
      "Training loss: 0.015798592939972878\n",
      "Validation loss: 0.04293503239750862\n",
      "Validation accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Train CoAtNet\n",
    "train = {'loss':[]}\n",
    "valid = {'loss':[],'accuracy':[],'specificity':[],'recall':[],'precision':[],'negpred':[],'f1':[]}\n",
    "\n",
    "epochs = 20 \n",
    "for eid in range(epochs):\n",
    "    # Logging\n",
    "    print(\"Epoch {}\".format(eid))\n",
    "    loss_avg = 0\n",
    "    for i, (inputs, targets) in enumerate(dataloaders[\"train\"]):\n",
    "        # Train model\n",
    "        model.train()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss_avg += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()   \n",
    "        # Logging\n",
    "    train['loss'].append(loss_avg/total_batches)\n",
    "    print(\"Training loss: {}\".format(loss_avg/total_batches))\n",
    "    # Validate model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        total = 0\n",
    "        loss_avg = 0\n",
    "        for i, (inputs, targets) in enumerate(dataloaders[\"valid\"]):\n",
    "            outputs = model(inputs)\n",
    "            loss_avg += loss_fn(outputs, targets)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            TP += ((predicted == targets)&(predicted == 1)).sum().item()\n",
    "            FP += ((predicted != targets)&(targets == 0)).sum().item()\n",
    "            TN += ((predicted == targets)&(predicted == 0)).sum().item()\n",
    "            FN += ((predicted != targets)&(targets == 1)).sum().item()\n",
    "        acc = div((TP+TN),total)\n",
    "        spec = div(TN,(TN+FP))\n",
    "        negpred = div(TN,(TN+FN))\n",
    "        rec = div(TP,(TP+FN))\n",
    "        prec = div(TP,(TP+FP))\n",
    "        f1 = div(2*(prec*rec),(prec+rec))\n",
    "        valid['accuracy'].append(acc) \n",
    "        valid['specificity'].append(spec) \n",
    "        valid['recall'].append(rec) \n",
    "        valid['precision'].append(prec) \n",
    "        valid['negpred'].append(negpred) \n",
    "        valid['f1'].append(f1) \n",
    "        valid['loss'].append(loss_avg/total_batches) \n",
    "        print(\"Validation loss: {}\".format(loss_avg/total_batches))\n",
    "        print(\"Validation accuracy: {}\".format(acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c6ffcc4e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "total = 0\n",
    "for i, (inputs, targets) in enumerate(dataloaders[\"test\"]):\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += targets.size(0)\n",
    "    correct += (predicted == targets).sum().item()\n",
    "    TP += ((predicted == targets)&(predicted == 1)).sum().item()\n",
    "    FP += ((predicted != targets)&(targets == 0)).sum().item()\n",
    "    TN += ((predicted == targets)&(predicted == 0)).sum().item()\n",
    "    FN += ((predicted != targets)&(targets == 1)).sum().item()\n",
    "acc = div((TP+TN),total)\n",
    "spec = div(TN,(TN+FP))\n",
    "negpred = div(TN,(TN+FN))\n",
    "rec = div(TP,(TP+FN))\n",
    "prec = div(TP,(TP+FP))\n",
    "f1 = div(2*(prec*rec),(prec+rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a1f6b4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.806\n",
      "Test specifity: 0.84\n",
      "Test negative predicable: 0.7865168539\n",
      "Test recall: 0.772\n",
      "Test precision: 0.8283261803\n",
      "Test f1: 0.7991718427\n",
      "TP: 193\n",
      "FP: 40\n",
      "TN: 210\n",
      "FN: 57\n"
     ]
    }
   ],
   "source": [
    "#CE, lr 0.00001, \n",
    "print(\"Test accuracy: {}\".format(round(acc,10)))\n",
    "print(\"Test specifity: {}\".format(round(spec,10)))\n",
    "print(\"Test negative predicable: {}\".format(round(negpred,10)))\n",
    "print(\"Test recall: {}\".format(round(rec,10)))\n",
    "print(\"Test precision: {}\".format(round(prec,10)))\n",
    "print(\"Test f1: {}\".format(round(f1,10)))\n",
    "print(\"TP:\",TP)\n",
    "print(\"FP:\",FP)\n",
    "print(\"TN:\",TN)\n",
    "print(\"FN:\",FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b5666a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.792\n",
      "Test specifity: 0.676\n",
      "Test negative predicable: 0.8802083333\n",
      "Test recall: 0.908\n",
      "Test precision: 0.737012987\n",
      "Test f1: 0.8136200717\n"
     ]
    }
   ],
   "source": [
    "#CE, lr 0.0003, \n",
    "print(\"Test accuracy: {}\".format(round(acc,10)))\n",
    "print(\"Test specifity: {}\".format(round(spec,10)))\n",
    "print(\"Test negative predicable: {}\".format(round(negpred,10)))\n",
    "print(\"Test recall: {}\".format(round(rec,10)))\n",
    "print(\"Test precision: {}\".format(round(prec,10)))\n",
    "print(\"Test f1: {}\".format(round(f1,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "95278d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 227\n",
      "FP: 81\n",
      "TN: 169\n",
      "FN: 23\n"
     ]
    }
   ],
   "source": [
    "print(\"TP:\",TP)\n",
    "print(\"FP:\",FP)\n",
    "print(\"TN:\",TN)\n",
    "print(\"FN:\",FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0fe9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gistar",
   "language": "python",
   "name": "gistar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
